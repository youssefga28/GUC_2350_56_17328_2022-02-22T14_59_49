{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35roXDEMudbw"
      },
      "source": [
        "# GUC Clustering Project "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCwbCzREudb1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIiItKbYudb2"
      },
      "source": [
        "**Objective:** \n",
        "The objective of this project teach students how to apply clustering to real data sets\n",
        "\n",
        "The projects aims to teach student: \n",
        "* Which clustering approach to use\n",
        "* Compare between Kmeans, Hierarchal, DBScan, and Gaussian Mixtures  \n",
        "* How to tune the parameters of each data approach\n",
        "* What is the effect of different distance functions (optional) \n",
        "* How to evaluate clustering approachs \n",
        "* How to display the output\n",
        "* What is the effect of normalizing the data \n",
        "\n",
        "Students in this project will use ready-made functions from Sklearn, plotnine, numpy and pandas \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MtHElDYdudb3"
      },
      "outputs": [],
      "source": [
        "# if plotnine is not installed in Jupter then use the following command to install it \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RHS5ZoQudb4"
      },
      "source": [
        "Running this project require the following imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QrueqJenudb5"
      },
      "outputs": [],
      "source": [
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "# import seaborn as sns \n",
        "# import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import sklearn.preprocessing as prep\n",
        "# from sklearn.datasets import make_blobs\n",
        "# from plotnine import *   \n",
        "# # StandardScaler is a function to normalize the data \n",
        "# # You may also check MinMaxScaler and MaxAbsScaler \n",
        "# #from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# from sklearn.cluster import DBSCAN\n",
        "\n",
        "# import sklearn\n",
        "# from sklearn.cluster import KMeans,AgglomerativeClustering\n",
        "# from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# from sklearn.metrics import silhouette_score\n",
        "\n",
        "# %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ju2Zj6-nudb5"
      },
      "outputs": [],
      "source": [
        "# # helper function that allows us to display data in 2 dimensions an highlights the clusters\n",
        "# def display_cluster(X,km=[],num_clusters=0,centers=True):\n",
        "#     color = ['b','r','g','c','m','y','k','#FFFF00','#F30F70','#9F4080']\n",
        "#     markers=['$0$','1','2','3','4','5','6','7','8','9']\n",
        "#     #List colors\n",
        "#     alpha = 0.5  #color obaque\n",
        "#     s = 20\n",
        "#     if num_clusters == 0:\n",
        "#         plt.scatter(X[:,0],X[:,1],c = color[0],alpha = alpha,s = s)\n",
        "#     else:\n",
        "#         for i in range(num_clusters):\n",
        "#             plt.scatter(X[km.labels_==i,0],X[km.labels_==i,1],c = color[i%len(color)],alpha = alpha,s=s*2,marker='$'+str((i//len(color))%10)+'$')\n",
        "#             if centers:\n",
        "#                 plt.scatter(km.cluster_centers_[i][0],km.cluster_centers_[i][1],c = color[i%len(color)], marker = 'x', s = 100)\n",
        "                \n",
        "# # helper function that allows us to display data in 2 dimensions an highlights the clusters\n",
        "# def display_dbcluster(X,km=[],num_clusters=0,centers=True):\n",
        "#     color = ['b','r','g','c','m','y','k','#FFFF00','#F30F70','#9F4080']\n",
        "#     markers=['$0$','1','2','3','4','5','6','7','8','9']\n",
        "#     out='#000000'\n",
        "#     #List colors\n",
        "#     alpha = 0.5  #color obaque\n",
        "#     s = 20\n",
        "#     if num_clusters == 0:\n",
        "#         plt.scatter(X[:,0],X[:,1],c = color[0],alpha = alpha,s = s)\n",
        "#     else:\n",
        "#         for i in np.unique(km.labels_):\n",
        "#             if i==-1:\n",
        "#                 plt.scatter(X[km.labels_==i,0],X[km.labels_==i,1],c =out,alpha = alpha,s=s*2,marker='$'+'n'+'$')\n",
        "#                 continue\n",
        "#             plt.scatter(X[km.labels_==i,0],X[km.labels_==i,1],c = color[i%len(color)],alpha = alpha,s=s*2,marker='$'+str((i//len(color))%10)+'$')\n",
        "            \n",
        "# def display_gmmcluster(X,labels=[],num_clusters=0):\n",
        "#     color = ['b','r','g','c','m','y','k','#FFFF00','#F30F70','#9F4080']\n",
        "#     markers=['$0$','1','2','3','4','5','6','7','8','9']\n",
        "#     #List colors\n",
        "#     alpha = 0.5  #color obaque\n",
        "#     s = 20\n",
        "#     if num_clusters == 0:\n",
        "#         plt.scatter(X[:,0],X[:,1],c = color[0],alpha = alpha,s = s)\n",
        "#     else:\n",
        "#         for i in np.unique(labels):\n",
        "#             plt.scatter(X[labels==i,0],X[labels==i,1],c = color[i%len(color)],alpha = alpha,s=s*2,marker='$'+str((i//len(color))%10)+'$')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from scipy.cluster.hierarchy import dendrogram\n",
        "# def plot_dendrogram(model, **kwargs):\n",
        "#     # Create linkage matrix and then plot the dendrogram\n",
        "\n",
        "#     # create the counts of samples under each node\n",
        "#     counts = np.zeros(model.children_.shape[0])\n",
        "#     n_samples = len(model.labels_)\n",
        "#     for i, merge in enumerate(model.children_):\n",
        "#         current_count = 0\n",
        "#         for child_idx in merge:\n",
        "#             if child_idx < n_samples:\n",
        "#                 current_count += 1  # leaf node\n",
        "#             else:\n",
        "#                 current_count += counts[child_idx - n_samples]\n",
        "#         counts[i] = current_count\n",
        "\n",
        "#     linkage_matrix = np.column_stack(\n",
        "#         [model.children_, model.distances_, counts]\n",
        "#     ).astype(float)\n",
        "\n",
        "#     # Plot the corresponding dendrogram\n",
        "#     dendrogram(linkage_matrix, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZnIbT3Mudb6"
      },
      "source": [
        "## Multi Blob Data Set \n",
        "* The Data Set generated below has 6 cluster with varying number of users and varing densities\n",
        "* Cluster the data set below using \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JeSqG318udb7",
        "outputId": "078fad92-3073-4558-b1e8-f0acd8d85d34"
      },
      "outputs": [],
      "source": [
        "# plt.rcParams['figure.figsize'] = [8,8]\n",
        "# sns.set_style(\"whitegrid\")\n",
        "# sns.set_context(\"talk\")\n",
        "\n",
        "# n_bins = 6  \n",
        "# centers = [(-3, -3), (0, 0), (5,2.5),(-1, 4), (4, 6), (9,7)]\n",
        "# Multi_blob_Data, y = make_blobs(n_samples=[100,150, 300, 400,300, 200], n_features=2, cluster_std=[1.3,0.6, 1.2, 1.7,0.9,1.7],\n",
        "#                   centers=centers, shuffle=False, random_state=42)\n",
        "# display_cluster(Multi_blob_Data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDSIGjubudb8"
      },
      "source": [
        "### Kmeans \n",
        "* Use Kmeans with different values of K to cluster the above data \n",
        "* Display the outcome of each value of K \n",
        "* Plot distortion function versus K and choose the approriate value of k \n",
        "* Plot the silhouette_score versus K and use it to choose the best K \n",
        "* Store the silhouette_score for the best K for later comparison with other clustering techniques. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# distortions=[]\n",
        "# for k in range(1,11):    \n",
        "#     kmeans=KMeans(n_clusters=k, init='random', n_init=10, max_iter=300, tol=1e-4,random_state=0)\n",
        "#     kmeans.fit(Multi_blob_Data)\n",
        "#     distortions.append(kmeans.inertia_)\n",
        "#     if k!=1:\n",
        "#         silhouettes.append(silhouette_score(Multi_blob_Data, kmeans.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title(str(k)+\" Clusters\")\n",
        "#     display_cluster(Multi_blob_Data,kmeans,num_clusters=k)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.title('Elbow Figure')\n",
        "# x1=np.arange(1,11)\n",
        "# x2=np.arange(2,11)\n",
        "# plt.plot(x1,distortions)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.plot(x2,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x2[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_Ne3KmtPudb9"
      },
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# distortions=[]\n",
        "# for k in range(1,11):    \n",
        "#     kmeans=KMeans(n_clusters=k, init='k-means++', n_init='auto', max_iter=300, tol=1e-4,random_state=0)\n",
        "#     kmeans.fit(Multi_blob_Data)\n",
        "#     distortions.append(kmeans.inertia_)\n",
        "#     if k!=1:\n",
        "#         silhouettes.append(silhouette_score(Multi_blob_Data, kmeans.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title(str(k)+\" Clusters\")\n",
        "#     display_cluster(Multi_blob_Data,kmeans,num_clusters=k)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.title('Elbow Figure')\n",
        "# x1=np.arange(1,11)\n",
        "# x2=np.arange(2,11)\n",
        "# plt.plot(x1,distortions)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.plot(x2,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x2[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE7dvpOAudb9"
      },
      "source": [
        "### Hierarchal Clustering\n",
        "* Use AgglomerativeClustering function to  to cluster the above data \n",
        "* In the  AgglomerativeClustering change the following parameters \n",
        "    * Affinity (use euclidean, manhattan and cosine)\n",
        "    * Linkage( use average and single )\n",
        "    * Distance_threshold (try different)\n",
        "* For each of these trials plot the Dendograph , calculate the silhouette_score and display the resulting clusters  \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3O_6WwKoudb-"
      },
      "outputs": [],
      "source": [
        "# from itertools import product\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "# for aff, linkage in product(affinities, linkages):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity=aff, linkage=linkage,distance_threshold=0)\n",
        "#     agg.fit(Multi_blob_Data)\n",
        "#     plt.figure()\n",
        "#     plt.title(aff+' Distance'+' and '+linkage+' linkage')\n",
        "#     plot_dendrogram(agg)\n",
        "\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in range(1,9):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='euclidean', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(Multi_blob_Data)\n",
        "#     silhouettes.append(silhouette_score(Multi_blob_Data, agg.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(1,9)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]+1\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.2,0.9,0.1):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='euclidean', linkage='single',distance_threshold=d)\n",
        "#     agg.fit(Multi_blob_Data)\n",
        "#     silhouettes.append(silhouette_score(Multi_blob_Data, agg.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title('Euclidean Distance'+' and single linkage '+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.2,0.9,0.1)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(2,11,1):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='manhattan', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(Multi_blob_Data)\n",
        "#     silhouettes.append(silhouette_score(Multi_blob_Data, agg.labels_,  metric='manhattan', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title('manhattan Distance'+' and average linkage '+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(2,11,1)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]+2\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.2,0.9,0.1):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='manhattan', linkage='single',distance_threshold=d)\n",
        "#     agg.fit(Multi_blob_Data)\n",
        "#     silhouettes.append(silhouette_score(Multi_blob_Data, agg.labels_,  metric='manhattan', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title('manhattan Distance'+' and single linkage '+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.2,0.9,0.1)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.1,1,0.1):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='cosine', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(Multi_blob_Data)\n",
        "#     silhouettes.append(silhouette_score(Multi_blob_Data, agg.labels_,  metric='cosine', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title('cosine Distance'+' and average linkage '+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.1,1,0.1)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.001,0.009,0.001):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='cosine', linkage='single',distance_threshold=d)\n",
        "#     agg.fit(Multi_blob_Data)\n",
        "#     silhouettes.append(silhouette_score(Multi_blob_Data, agg.labels_,  metric='cosine', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title('cosine Distance'+' and single linkage '+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.001,0.009,0.001)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myJE7vQKudb-"
      },
      "source": [
        "### DBScan\n",
        "* Use DBScan function to  to cluster the above data \n",
        "* In the  DBscan change the following parameters \n",
        "    * EPS (from 0.1 to 3)\n",
        "    * Min_samples (from 5 to 25)\n",
        "* Plot the silhouette_score versus the variation in the EPS and the min_samples\n",
        "* Plot the resulting Clusters in this case \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observations and comments "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QiQtpAt5udb_"
      },
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "# values=[]\n",
        "\n",
        "# for eps1 in np.arange(0.3,1.3,0.1): \n",
        "#     for min_s in range(5,26,5):\n",
        "#         dbscan=DBSCAN(eps=eps1,min_samples=min_s)\n",
        "#         dbscan.fit(Multi_blob_Data)\n",
        "#         #print(Multi_blob_Data[dbscan.labels_!=-1,:].shape)\n",
        "#         #print(dbscan.labels_[dbscan.labels_!= -1].shape)\n",
        "#         if len(np.unique(dbscan.labels_[dbscan.labels_!= -1]))>=2:\n",
        "#             silhouettes.append(silhouette_score(Multi_blob_Data, dbscan.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#             values.append((eps1,min_s))\n",
        "#         plt.figure()\n",
        "#         plt.title(str(eps1)+' eps'+' and'+str(min_s)+' samples ')\n",
        "#         display_dbcluster(Multi_blob_Data,dbscan,num_clusters=len(np.unique(dbscan.labels_)),centers=False)\n",
        "#         #print(np.unique(dbscan.labels_))\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# #x=np.arange(0.001,0.009,0.001)\n",
        "# plt.plot(silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=values[np.argmax(np.array(silhouettes))]\n",
        "\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip16g1QFudb_"
      },
      "source": [
        "### Gaussian Mixture\n",
        "* Use GaussianMixture function to cluster the above data \n",
        "* In GMM change the covariance_type and check the difference in the resulting proabability fit \n",
        "* Use a 2D contour plot to plot the resulting distribution (the components of the GMM) as well as the total Gaussian mixture "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "def plot_gmm_contour(gmm,X, n_components=2, levels=10, cmap='viridis'):\n",
        "    \"\"\"\n",
        "    Plot a contour map for a Gaussian Mixture Model (GMM) with different colors for each cluster.\n",
        "\n",
        "    Parameters:\n",
        "    - X: Input data (numpy array).\n",
        "    - n_components: Number of components (clusters) in the GMM.\n",
        "    - levels: Number of contour levels.\n",
        "    - cmap: Colormap for contour lines and cluster colors.\n",
        "\n",
        "    Returns:\n",
        "    - None (displays the plot).\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a meshgrid to plot the contours\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
        "\n",
        "    # Predict the GMM clusters for each point in the meshgrid\n",
        "    Z = -gmm.score_samples(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Plot the contour map with different colors for each cluster and multiple contour levels\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.contour(xx, yy, Z, levels=np.logspace(0, levels, num=20*levels), cmap=cmap, norm=LogNorm())\n",
        "    plt.scatter(X[:, 0], X[:, 1], marker='o', c=gmm.predict(X), cmap=cmap, alpha=0.7)\n",
        "    plt.colorbar()\n",
        "    plt.title('GMM Contour Map with Clusters')\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='full')\n",
        "#     x=GMM.fit_predict(Multi_blob_Data)\n",
        "#     silhouettes.append(silhouette_score(Multi_blob_Data, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plot_gmm_contour(GMM,Multi_blob_Data)\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='tied')\n",
        "#     x=GMM.fit_predict(Multi_blob_Data)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(Multi_blob_Data, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plot_gmm_contour(GMM,Multi_blob_Data)\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='diag')\n",
        "#     x=GMM.fit_predict(Multi_blob_Data)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(Multi_blob_Data, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plot_gmm_contour(GMM,Multi_blob_Data)\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='spherical')\n",
        "#     x=GMM.fit_predict(Multi_blob_Data)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(Multi_blob_Data, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plot_gmm_contour(GMM,Multi_blob_Data)\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m92lZkkyudb_"
      },
      "source": [
        "## iris data set \n",
        "The iris data set is test data set that is part of the Sklearn module \n",
        "which contains 150 records each with 4 features. All the features are represented by real numbers \n",
        "\n",
        "The data represents three classes \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_QaCWyyCudcA",
        "outputId": "79c14dba-80cf-4d96-e69d-70763b789faf"
      },
      "outputs": [],
      "source": [
        "# from sklearn.datasets import load_iris\n",
        "# iris_data = load_iris()\n",
        "# print(iris_data)\n",
        "# iris_data.target[[10, 25, 50]]\n",
        "# #array([0, 0, 1])\n",
        "# target_names=iris_data.target_names\n",
        "# print(target_names)\n",
        "# ['setosa', 'versicolor', 'virginica']\n",
        "# iris_data=iris_data.data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import perm\n",
        "from itertools import combinations\n",
        "\n",
        "def calculate_rows_columns(number):\n",
        "    rows = 1\n",
        "    columns = number\n",
        "\n",
        "    for i in range(2, int(number**0.5) + 1):\n",
        "        if number % i == 0:\n",
        "            rows = i\n",
        "            columns = number // i\n",
        "\n",
        "    return rows, columns\n",
        "def display_cluster2(X,num_clusters=0,indeces=[],km=[],title=''):\n",
        "    color = ['b','r','g','c','m','y','k','#FFFF00','#F00F00','#0FF0F0']  #List colors\n",
        "    alpha = 0.5  #color obaque\n",
        "    s = 20\n",
        "    combinations_result = list(combinations(np.arange(X.shape[1]), 2))\n",
        "    nrows,ncols=calculate_rows_columns(len(combinations_result))\n",
        "    if len(combinations_result)==1:\n",
        "        display_cluster(X,km,num_clusters,indeces)\n",
        "        return\n",
        "    if num_clusters == 0:\n",
        "        for iteration in combinations_result:\n",
        "            axs[row,col].scatter(X[:,iteration[0]],X[:,iteration[1]],c = color[0],alpha = alpha,s=s)\n",
        "            axs[row,col].set_title(title) \n",
        "            if col==ncols-1:\n",
        "                col=0\n",
        "                row=row+1\n",
        "            else:\n",
        "                col=col+1\n",
        "    else:\n",
        "\n",
        "      fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 20))\n",
        "      row=0\n",
        "      col=0\n",
        "      for iteration in combinations_result:\n",
        "        for i in range(num_clusters):\n",
        "            axs[row,col].scatter(X[np.where(indeces==i),iteration[0]],X[np.where(indeces==i),iteration[1]],c = color[i%len(color)],alpha = alpha,s=s)\n",
        "            axs[row,col].set_title(title)\n",
        "            #plt.scatter(km.cluster_centers_[i][0],km.cluster_centers_[i][1],c = color[i], marker = 'x', s = 100)\n",
        "            \n",
        "        if col==ncols-1:\n",
        "            col=0\n",
        "            row=row+1\n",
        "        else:\n",
        "            col=col+1\n",
        "def display_dbcluster2(X,km=[],num_clusters=0,indeces=[],title=''):\n",
        "    color = ['b','r','g','c','m','y','k','#FFFF00','#F00F00','#0FF0F0']  #List colors\n",
        "    alpha = 0.5  #color obaque\n",
        "    s = 20\n",
        "    combinations_result = list(combinations(np.arange(X.shape[1]), 2))\n",
        "    nrows,ncols=calculate_rows_columns(len(combinations_result))\n",
        "    if len(combinations_result)==1:\n",
        "        display_dbcluster(X,km,num_clusters,indeces)\n",
        "        return\n",
        "    if num_clusters == 0:\n",
        "        for iteration in combinations_result:\n",
        "            axs[row,col].scatter(X[:,iteration[0]],X[:,iteration[1]],c = color[0],alpha = alpha,s=s)\n",
        "            axs[row,col].set_title(title) \n",
        "            if col==ncols-1:\n",
        "                col=0\n",
        "                row=row+1\n",
        "            else:\n",
        "                col=col+1\n",
        "    else:\n",
        "\n",
        "      fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 20))\n",
        "      row=0\n",
        "      col=0\n",
        "      for iteration in combinations_result:\n",
        "        for i in np.unique(indeces):\n",
        "            if i==-1:\n",
        "                axs[row,col].scatter(X[np.where(indeces==i),iteration[0]],X[np.where(indeces==i),iteration[1]],c = '#000000',alpha = alpha,s=s,marker='$'+'n'+'$')\n",
        "            else:    \n",
        "                axs[row,col].scatter(X[np.where(indeces==i),iteration[0]],X[np.where(indeces==i),iteration[1]],c = color[i%len(color)],alpha = alpha,s=s*2,marker='$'+str((i//len(color))%10)+'$')\n",
        "            axs[row,col].set_title(title)\n",
        "            #plt.scatter(km.cluster_centers_[i][0],km.cluster_centers_[i][1],c = color[i], marker = 'x', s = 100)\n",
        "            \n",
        "        if col==ncols-1:\n",
        "            col=0\n",
        "            row=row+1\n",
        "        else:\n",
        "            col=col+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# distortions=[]\n",
        "# for k in range(1,11):    \n",
        "#     kmeans=KMeans(n_clusters=k, init='k-means++',tol=1e-4,random_state=0)\n",
        "#     kmeans.fit(iris_data)\n",
        "#     distortions.append(kmeans.inertia_)\n",
        "#     if k!=1:\n",
        "#         silhouettes.append(silhouette_score(iris_data, kmeans.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plt.figure()\n",
        "#     #plt.title(str(k)+\" Clusters\")\n",
        "#     display_cluster2(iris_data,num_clusters=len(np.unique(kmeans.labels_)),indeces=kmeans.labels_)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.title('Elbow Figure')\n",
        "# x1=np.arange(1,11)\n",
        "# x2=np.arange(2,11)\n",
        "# plt.plot(x1,distortions)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.plot(x2,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x2[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from itertools import product\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "# for aff, linkage in product(affinities, linkages):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity=aff, linkage=linkage,distance_threshold=0)\n",
        "#     agg.fit(iris_data)\n",
        "#     plt.figure()\n",
        "#     plt.title(aff+' Distance'+' and '+linkage+' linkage')\n",
        "#     plot_dendrogram(agg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.5,2.6,0.5):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='euclidean', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(iris_data)\n",
        "#     silhouettes.append(silhouette_score(iris_data, agg.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_data,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='Euclidean Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.5,2.6,0.5)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.2,1.1,0.2):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='euclidean', linkage='single',distance_threshold=d)\n",
        "#     agg.fit(iris_data)\n",
        "#     silhouettes.append(silhouette_score(iris_data, agg.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_data,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='Euclidean Distance'+' and single linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.2,1.1,0.2)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(1,4.1,1):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='manhattan', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(iris_data)\n",
        "#     silhouettes.append(silhouette_score(iris_data, agg.labels_,  metric='manhattan', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_data,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='manhattan Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(1,4.1,1)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.1,1.6,0.2):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='manhattan', linkage='single',distance_threshold=d)\n",
        "#     agg.fit(iris_data)\n",
        "#     silhouettes.append(silhouette_score(iris_data, agg.labels_,  metric='manhattan', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_data,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='manhattan Distance'+' and single linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.1,1.6,0.2)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.001,0.02,0.003):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='cosine', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(iris_data)\n",
        "#     silhouettes.append(silhouette_score(iris_data, agg.labels_,  metric='cosine', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_data,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='cosine Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.001,0.02,0.003)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.001,0.005,0.0005):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='cosine', linkage='single',distance_threshold=d)\n",
        "#     agg.fit(iris_data)\n",
        "#     silhouettes.append(silhouette_score(iris_data, agg.labels_,  metric='cosine', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_data,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='cosine Distance'+' and single linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.001,0.005,0.0005)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# values=[]\n",
        "\n",
        "# for eps1 in np.arange(0.3,1.3,0.1): \n",
        "#     for min_s in range(5,26,5):\n",
        "#         dbscan=DBSCAN(eps=eps1,min_samples=min_s)\n",
        "#         dbscan.fit(iris_data)\n",
        "#         #print(Multi_blob_Data[dbscan.labels_!=-1,:].shape)\n",
        "#         #print(dbscan.labels_[dbscan.labels_!= -1].shape)\n",
        "#         if len(np.unique(dbscan.labels_[dbscan.labels_!= -1]))>=2:\n",
        "#             silhouettes.append(silhouette_score(iris_data, dbscan.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#             values.append((eps1,min_s))\n",
        "#         print(np.unique(dbscan.labels_))\n",
        "#         display_dbcluster2(iris_data,indeces=dbscan.labels_,num_clusters=len(np.unique(dbscan.labels_)),title=str(eps1)+' eps and '+str(min_s)+'\\n samples and '+str(len(np.unique(dbscan.labels_)))+' clusters')\n",
        "#         #print(np.unique(dbscan.labels_))\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# #x=np.arange(0.001,0.009,0.001)\n",
        "# plt.plot(silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=values[np.argmax(np.array(silhouettes))]\n",
        "\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def plot_gmm_contour2(gmm, X, n_components=2, levels=10, cmap='viridis',title=''):\n",
        "#     \"\"\"\n",
        "#     Plot contour maps for a Gaussian Mixture Model (GMM) with different colors for each cluster.\n",
        "\n",
        "#     Parameters:\n",
        "#     - X: Input data (numpy array).\n",
        "#     - n_components: Number of components (clusters) in the GMM.\n",
        "#     - levels: Number of contour levels.\n",
        "#     - cmap: Colormap for contour lines and cluster colors.\n",
        "\n",
        "#     Returns:\n",
        "#     - None (displays the plot).\n",
        "#     \"\"\"\n",
        "\n",
        "#     n_dims = X.shape[1]\n",
        "\n",
        "#     # Create subplots for each pair of dimensions\n",
        "#     fig, axs = plt.subplots(n_dims - 1, n_dims - 1, figsize=(12, 12))\n",
        "\n",
        "#     for i in range(n_dims - 1):\n",
        "#         for j in range(i + 1, n_dims):\n",
        "#             # Create a meshgrid for the current pair of dimensions\n",
        "#             x_min, x_max = X[:, i].min() - 1, X[:, i].max() + 1\n",
        "#             y_min, y_max = X[:, j].min() - 1, X[:, j].max() + 1\n",
        "#             xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
        "\n",
        "#             # Predict the GMM clusters for each point in the meshgrid\n",
        "#             points = np.c_[xx.ravel(), yy.ravel()]\n",
        "#             Z = -gmm.score_samples(np.hstack((points, np.zeros((len(points), n_dims - 2)))))\n",
        "\n",
        "#             Z = Z.reshape(xx.shape)\n",
        "\n",
        "#             # Plot the contour map with different colors for each cluster and multiple contour levels\n",
        "#             axs[i, j - 1].contour(xx, yy, Z, levels=np.logspace(0, levels, num=20 * levels), cmap=cmap, norm=LogNorm())\n",
        "#             axs[i, j - 1].scatter(X[:, i], X[:, j], marker='o', c=gmm.predict(X), cmap=cmap, alpha=0.7)\n",
        "#             axs[i, j - 1].set_title(title)\n",
        "#             axs[i, j - 1].set_xlabel(f'Feature {i + 1}')\n",
        "#             axs[i, j - 1].set_ylabel(f'Feature {j + 1}')\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='tied')\n",
        "#     x=GMM.fit_predict(iris_data)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(iris_data, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plot_gmm_contour2(GMM,iris_data,title='tied and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='full')\n",
        "#     x=GMM.fit_predict(iris_data)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(iris_data, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plot_gmm_contour2(GMM,iris_data,title='full and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='diag')\n",
        "#     x=GMM.fit_predict(iris_data)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(iris_data, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plot_gmm_contour2(GMM,iris_data,title='diag and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='spherical')\n",
        "#     x=GMM.fit_predict(iris_data)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(iris_data, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plot_gmm_contour2(GMM,iris_data,title='spherical and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# # Initialize the StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "\n",
        "# # Fit the scaler to your data and transform it\n",
        "# iris_standardized = scaler.fit_transform(iris_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# distortions=[]\n",
        "# for k in range(1,11):    \n",
        "#     kmeans=KMeans(n_clusters=k, init='k-means++',tol=1e-4,random_state=0)\n",
        "#     kmeans.fit(iris_standardized)\n",
        "#     distortions.append(kmeans.inertia_)\n",
        "#     if k!=1:\n",
        "#         silhouettes.append(silhouette_score(iris_standardized, kmeans.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plt.figure()\n",
        "#     #plt.title(str(k)+\" Clusters\")\n",
        "#     display_cluster2(iris_standardized,num_clusters=len(np.unique(kmeans.labels_)),indeces=kmeans.labels_)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.title('Elbow Figure')\n",
        "# x1=np.arange(1,11)\n",
        "# x2=np.arange(2,11)\n",
        "# plt.plot(x1,distortions)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.plot(x2,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x2[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from itertools import product\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "# for aff, linkage in product(affinities, linkages):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity=aff, linkage=linkage,distance_threshold=0)\n",
        "#     agg.fit(iris_standardized)\n",
        "#     plt.figure()\n",
        "#     plt.title(aff+' Distance'+' and '+linkage+' linkage')\n",
        "#     plot_dendrogram(agg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for d in np.arange(0.5,3.1,0.4):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='euclidean', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(iris_standardized)\n",
        "#     silhouettes.append(silhouette_score(iris_standardized, agg.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_standardized,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='euclidean Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.5,3.1,0.4)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for d in np.arange(0.4,1.1,0.1):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='euclidean', linkage='single',distance_threshold=d)\n",
        "#     agg.fit(iris_standardized)\n",
        "#     silhouettes.append(silhouette_score(iris_standardized, agg.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_standardized,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='euclidean Distance'+' and single linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.4,1.1,0.1)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for d in np.arange(1,4.4,0.4):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='manhattan', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(iris_standardized)\n",
        "#     silhouettes.append(silhouette_score(iris_standardized, agg.labels_,  metric='manhattan', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_standardized,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='manhattan Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(1,4.4,0.4)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for d in np.arange(0.5,2.1,0.5):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='manhattan', linkage='single',distance_threshold=d)\n",
        "#     agg.fit(iris_standardized)\n",
        "#     silhouettes.append(silhouette_score(iris_standardized, agg.labels_,  metric='manhattan', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_standardized,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='manhattan Distance'+' and single linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.5,2.1,0.5)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for d in np.arange(0.1,1.1,0.1):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='cosine', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(iris_standardized)\n",
        "#     silhouettes.append(silhouette_score(iris_standardized, agg.labels_,  metric='cosine', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_standardized,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='cosine Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.1,1.1,0.1)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for d in np.arange(0.01,0.1,0.01):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='cosine', linkage='single',distance_threshold=d)\n",
        "#     agg.fit(iris_standardized)\n",
        "#     silhouettes.append(silhouette_score(iris_standardized, agg.labels_,  metric='cosine', sample_size=None, random_state=0))\n",
        "#     #plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster2(iris_standardized,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='cosine Distance'+' and single linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     #display_cluster2(Multi_blob_Data,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.01,0.1,0.01)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# values=[]\n",
        "\n",
        "# for eps1 in np.arange(0.3,1.3,0.1): \n",
        "#     for min_s in range(5,26,5):\n",
        "#         dbscan=DBSCAN(eps=eps1,min_samples=min_s)\n",
        "#         dbscan.fit(iris_standardized)\n",
        "#         #print(Multi_blob_Data[dbscan.labels_!=-1,:].shape)\n",
        "#         #print(dbscan.labels_[dbscan.labels_!= -1].shape)\n",
        "#         if len(np.unique(dbscan.labels_[dbscan.labels_!= -1]))>=2:\n",
        "#             silhouettes.append(silhouette_score(iris_standardized, dbscan.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#             values.append((eps1,min_s))\n",
        "#         display_dbcluster2(iris_standardized,indeces=dbscan.labels_,num_clusters=len(np.unique(dbscan.labels_)),title=str(eps1)+' eps and '+str(min_s)+'\\n samples and '+str(len(np.unique(dbscan.labels_)))+' clusters')\n",
        "#         #print(np.unique(dbscan.labels_))\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# #x=np.arange(0.001,0.009,0.001)\n",
        "# plt.plot(silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=values[np.argmax(np.array(silhouettes))]\n",
        "\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='tied')\n",
        "#     x=GMM.fit_predict(iris_standardized)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(iris_standardized, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plot_gmm_contour2(GMM,iris_standardized,title='tied and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='full')\n",
        "#     x=GMM.fit_predict(iris_standardized)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(iris_standardized, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plot_gmm_contour2(GMM,iris_standardized,title='full and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='diag')\n",
        "#     x=GMM.fit_predict(iris_standardized)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(iris_standardized, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plot_gmm_contour2(GMM,iris_standardized,title='diag and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='spherical')\n",
        "#     x=GMM.fit_predict(iris_standardized)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(iris_standardized, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plot_gmm_contour2(GMM,iris_standardized,title='spherical and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyoCVfyMudcA"
      },
      "source": [
        "* Repeat all the above clustering approaches and steps on the above data \n",
        "* Normalize the data then repeat all the above steps \n",
        "* Compare between the different clustering approaches "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2oBmWT2udcA"
      },
      "source": [
        "## Customer dataset\n",
        "Repeat all the above on the customer data set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.decomposition import PCA\n",
        "# # Specify the path to your CSV file\n",
        "# csv_file_path = \"Customer data.csv\"\n",
        "\n",
        "# # Read the CSV file into a DataFrame using pandas\n",
        "# df = pd.read_csv(csv_file_path)\n",
        "# df = df.drop('ID', axis=1)\n",
        "# # Display the DataFrame\n",
        "# scaler = StandardScaler()\n",
        "# df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "# #pca = PCA(n_components=2)\n",
        "# #principal_components = pca.fit_transform(df_standardized)\n",
        "\n",
        "# #numpy_df=principal_components\n",
        "# customer_standard=df_standardized.to_numpy()\n",
        "# customer=df.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# distortions=[]\n",
        "# for k in range(1,11):    \n",
        "#     kmeans=KMeans(n_clusters=k, init='k-means++',tol=1e-4,random_state=0)\n",
        "#     kmeans.fit(customer)\n",
        "#     distortions.append(kmeans.inertia_)\n",
        "#     if k!=1:\n",
        "#         silhouettes.append(silhouette_score(customer, kmeans.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plt.figure()\n",
        "#     #plt.title(str(k)+\" Clusters\")\n",
        "#     display_cluster2(customer,num_clusters=len(np.unique(kmeans.labels_)),indeces=kmeans.labels_)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.title('Elbow Figure')\n",
        "# x1=np.arange(1,11)\n",
        "# x2=np.arange(2,11)\n",
        "# plt.plot(x1,distortions)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.plot(x2,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x2[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from itertools import product\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "# for aff, linkage in product(affinities, linkages):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity=aff, linkage=linkage,distance_threshold=0)\n",
        "#     agg.fit(customer)\n",
        "#     plt.figure()\n",
        "#     plt.title(aff+' Distance'+' and '+linkage+' linkage')\n",
        "#     plot_dendrogram(agg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(25000,80000,10000):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='euclidean', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(customer)\n",
        "#     silhouettes.append(silhouette_score(customer, agg.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #display_cluster2(customer,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='Euclidean Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(25000,80000,10000)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(10000,75000,10000):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='manhattan', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(customer)\n",
        "#     silhouettes.append(silhouette_score(customer, agg.labels_,  metric='manhattan', sample_size=None, random_state=0))\n",
        "#     #display_cluster2(customer,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='manhattan Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(10000,75000,10000)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.01e-7,0.5e-7,0.05e-7):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='cosine', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(customer)\n",
        "#     silhouettes.append(silhouette_score(customer, agg.labels_,  metric='cosine', sample_size=None, random_state=0))\n",
        "#     #display_cluster2(customer,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='cosine Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.01e-7,0.5e-7,0.05e-7)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "##DBScan couldnt work properly with non standardized data due to not knowing a good epsilon\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='full')\n",
        "#     x=GMM.fit_predict(customer)\n",
        "#     #plt.figure()\n",
        "#     silhouettes.append(silhouette_score(customer, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plot_gmm_contour2(GMM,customer,title='full and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='tied')\n",
        "#     x=GMM.fit_predict(customer)\n",
        "#     #plt.figure()\n",
        "#     silhouettes.append(silhouette_score(customer, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plot_gmm_contour2(GMM,customer,title='full and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='diag')\n",
        "#     x=GMM.fit_predict(customer)\n",
        "#     #plt.figure()\n",
        "#     silhouettes.append(silhouette_score(customer, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plot_gmm_contour2(GMM,customer,title='diag and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='spherical')\n",
        "#     x=GMM.fit_predict(customer)\n",
        "#     #plt.figure()\n",
        "#     silhouettes.append(silhouette_score(customer, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plot_gmm_contour2(GMM,customer,title='diag and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# distortions=[]\n",
        "# for k in range(1,11):    \n",
        "#     kmeans=KMeans(n_clusters=k, init='k-means++',tol=1e-4,random_state=0)\n",
        "#     kmeans.fit(customer_standard)\n",
        "#     distortions.append(kmeans.inertia_)\n",
        "#     if k!=1:\n",
        "#         silhouettes.append(silhouette_score(customer_standard, kmeans.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plt.figure()\n",
        "#     #plt.title(str(k)+\" Clusters\")\n",
        "#     display_cluster2(customer_standard,num_clusters=len(np.unique(kmeans.labels_)),indeces=kmeans.labels_)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.title('Elbow Figure')\n",
        "# x1=np.arange(1,11)\n",
        "# x2=np.arange(2,11)\n",
        "# plt.plot(x1,distortions)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.plot(x2,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x2[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from itertools import product\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "# for aff, linkage in product(affinities, linkages):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity=aff, linkage=linkage,distance_threshold=0)\n",
        "#     agg.fit(customer_standard)\n",
        "#     plt.figure()\n",
        "#     plt.title(aff+' Distance'+' and '+linkage+' linkage')\n",
        "#     plot_dendrogram(agg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(1,6,0.5):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='euclidean', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(customer_standard)\n",
        "#     silhouettes.append(silhouette_score(customer_standard, agg.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #display_cluster2(customer,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='euclidean Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(1,6,0.5)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.1,2.3,0.3):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='euclidean', linkage='single',distance_threshold=d)\n",
        "#     agg.fit(customer_standard)\n",
        "#     silhouettes.append(silhouette_score(customer_standard, agg.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #display_cluster2(customer,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='euclidean Distance'+' and single linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.1,2.3,0.3)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(1,9,1):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='manhattan', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(customer_standard)\n",
        "#     silhouettes.append(silhouette_score(customer_standard, agg.labels_,  metric='manhattan', sample_size=None, random_state=0))\n",
        "#     #display_cluster2(customer,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='manhattan Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(1,9,1)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.1,1.2,0.1):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='cosine', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(customer_standard)\n",
        "#     silhouettes.append(silhouette_score(customer_standard, agg.labels_,  metric='cosine', sample_size=None, random_state=0))\n",
        "#     #display_cluster2(customer,num_clusters=agg.n_clusters_,indeces=agg.labels_,title='cosine Distance'+' and average linkage'+' \\n and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.1,1.2,0.1)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# values=[]\n",
        "\n",
        "# for eps1 in np.arange(0.3,3,0.4): \n",
        "#     for min_s in range(5,26,7):\n",
        "#         dbscan=DBSCAN(eps=eps1,min_samples=min_s)\n",
        "#         dbscan.fit(customer_standard)\n",
        "#         #print(Multi_blob_Data[dbscan.labels_!=-1,:].shape)\n",
        "#         #print(dbscan.labels_[dbscan.labels_!= -1].shape)\n",
        "#         if len(np.unique(dbscan.labels_[dbscan.labels_!= -1]))>=2:\n",
        "#             silhouettes.append(silhouette_score(customer_standard, dbscan.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#             values.append((eps1,min_s))\n",
        "#         display_dbcluster2(customer_standard,indeces=dbscan.labels_,num_clusters=len(np.unique(dbscan.labels_)),title=str(eps1)+' eps and '+str(min_s)+'\\n samples and '+str(len(np.unique(dbscan.labels_)))+' clusters')\n",
        "#         #print(np.unique(dbscan.labels_))\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# #x=np.arange(0.001,0.009,0.001)\n",
        "# plt.plot(silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=values[np.argmax(np.array(silhouettes))]\n",
        "\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='full')\n",
        "#     x=GMM.fit_predict(customer_standard)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(customer_standard, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plot_gmm_contour2(GMM,customer_standard,title='full and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='tied')\n",
        "#     x=GMM.fit_predict(customer_standard)\n",
        "#     plt.figure()\n",
        "#     silhouettes.append(silhouette_score(customer_standard, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plot_gmm_contour2(GMM,customer_standard,title='full and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='diag')\n",
        "#     x=GMM.fit_predict(customer_standard)\n",
        "#     #plt.figure()\n",
        "#     silhouettes.append(silhouette_score(customer_standard, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plot_gmm_contour2(GMM,customer_standard,title='full and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='spherical')\n",
        "#     x=GMM.fit_predict(customer_standard)\n",
        "#     #plt.figure()\n",
        "#     silhouettes.append(silhouette_score(customer_standard, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     #plot_gmm_contour2(GMM,customer_standard,title='full and '+str(k)+' components')\n",
        "\n",
        "# plt.figure()\n",
        "# x=range(2,10)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(silhouettes)\n",
        "# best_silhouette_num=x[np.argmax(silhouettes)]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pca = PCA(n_components=2)\n",
        "# customer_pca = pca.fit_transform(df_standardized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# distortions=[]\n",
        "# for k in range(1,11):    \n",
        "#     kmeans=KMeans(n_clusters=k, init='k-means++', n_init='auto', max_iter=300, tol=1e-4,random_state=0)\n",
        "#     kmeans.fit(customer_pca)\n",
        "#     distortions.append(kmeans.inertia_)\n",
        "#     if k!=1:\n",
        "#         silhouettes.append(silhouette_score(customer_pca, kmeans.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title(str(k)+\" Clusters\")\n",
        "#     display_cluster(customer_pca,kmeans,num_clusters=k)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.title('Elbow Figure')\n",
        "# x1=np.arange(1,11)\n",
        "# x2=np.arange(2,11)\n",
        "# plt.plot(x1,distortions)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# plt.plot(x2,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x2[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from itertools import product\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "# for aff, linkage in product(affinities, linkages):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity=aff, linkage=linkage,distance_threshold=0)\n",
        "#     agg.fit(customer_pca)\n",
        "#     plt.figure()\n",
        "#     plt.title(aff+' Distance'+' and '+linkage+' linkage')\n",
        "#     plot_dendrogram(agg)\n",
        "\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.5,3.5,0.5):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='euclidean', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(customer_pca)\n",
        "#     silhouettes.append(silhouette_score(customer_pca, agg.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title('Euclidean Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster(customer_pca,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.5,3.5,0.5)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(1,4.5,0.5):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='manhattan', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(customer_pca)\n",
        "#     silhouettes.append(silhouette_score(customer_pca, agg.labels_,  metric='manhattan', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title('manhattan Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster(customer_pca,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(1,4.5,0.5)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "\n",
        "# for d in np.arange(0.1,1.1,0.1):    \n",
        "#     agg=AgglomerativeClustering(n_clusters=None,affinity='cosine', linkage='average',distance_threshold=d)\n",
        "#     agg.fit(customer_pca)\n",
        "#     silhouettes.append(silhouette_score(customer_pca, agg.labels_,  metric='cosine', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plt.title('cosine Distance'+' and average linkage'+'and Distance '+ str(d)+', '+str(agg.n_clusters_)+' Clusters')\n",
        "#     display_cluster(customer_pca,agg,num_clusters=agg.n_clusters_,centers=False)\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# x=np.arange(0.1,1.1,0.1)\n",
        "# plt.plot(x,silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# affinities=['euclidean','manhattan','cosine']\n",
        "# linkages=['average','single']\n",
        "# values=[]\n",
        "\n",
        "# for eps1 in np.arange(0.1,1.3,0.1): \n",
        "#     for min_s in range(5,26,5):\n",
        "#         dbscan=DBSCAN(eps=eps1,min_samples=min_s)\n",
        "#         dbscan.fit(customer_pca)\n",
        "#         #print(Multi_blob_Data[dbscan.labels_!=-1,:].shape)\n",
        "#         #print(dbscan.labels_[dbscan.labels_!= -1].shape)\n",
        "#         if len(np.unique(dbscan.labels_[dbscan.labels_!= -1]))>=2:\n",
        "#             silhouettes.append(silhouette_score(customer_pca, dbscan.labels_,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#             values.append((eps1,min_s))\n",
        "#         plt.figure()\n",
        "#         plt.title(str(eps1)+' eps'+' and'+str(min_s)+' samples ')\n",
        "#         display_dbcluster(customer_pca,dbscan,num_clusters=len(np.unique(dbscan.labels_)),centers=False)\n",
        "#         #print(np.unique(dbscan.labels_))\n",
        "# #x2=np.arange(2,11)\n",
        "# plt.figure()\n",
        "# plt.grid()\n",
        "# #x=np.arange(0.001,0.009,0.001)\n",
        "# plt.plot(silhouettes)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=values[np.argmax(np.array(silhouettes))]\n",
        "\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)\n",
        "                       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='full')\n",
        "#     x=GMM.fit_predict(customer_pca)\n",
        "#     silhouettes.append(silhouette_score(customer_pca, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plot_gmm_contour(GMM,customer_pca)\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)\n",
        "# x=range(2,10)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='tied')\n",
        "#     x=GMM.fit_predict(customer_pca)\n",
        "#     silhouettes.append(silhouette_score(customer_pca, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plot_gmm_contour(GMM,customer_pca)\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)\n",
        "# x=range(2,10)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='diag')\n",
        "#     x=GMM.fit_predict(customer_pca)\n",
        "#     silhouettes.append(silhouette_score(customer_pca, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plot_gmm_contour(GMM,customer_pca)\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)\n",
        "# x=range(2,10)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouettes=[]\n",
        "# for k in range (2,10):\n",
        "#     GMM=GaussianMixture(n_components=k,covariance_type='spherical')\n",
        "#     x=GMM.fit_predict(customer_pca)\n",
        "#     silhouettes.append(silhouette_score(customer_pca, x,  metric='euclidean', sample_size=None, random_state=0))\n",
        "#     plt.figure()\n",
        "#     plot_gmm_contour(GMM,customer_pca)\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(range(2,10),silhouettes)\n",
        "# x=range(2,10)\n",
        "# best_silhouette=np.max(np.array(silhouettes))\n",
        "# best_silhouette_num=x[np.argmax(np.array(silhouettes))]\n",
        "\n",
        "# print(best_silhouette)\n",
        "# print(best_silhouette_num)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Clustering Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
